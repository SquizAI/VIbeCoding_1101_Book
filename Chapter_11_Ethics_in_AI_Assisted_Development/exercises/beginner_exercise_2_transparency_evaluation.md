# Beginner Exercise 2: Transparency Evaluation

## Overview

This exercise helps you develop skills in evaluating and enhancing the transparency of AI-generated code. Transparency is a key ethical dimension of AI-assisted development, affecting stakeholder understanding, developer agency, and long-term maintainability.

## Objectives

- Learn to assess the transparency of AI-generated code across multiple dimensions
- Identify common transparency issues in AI-assisted development
- Practice techniques for improving code transparency
- Develop documentation strategies that enhance understanding

## Exercise

### Part 1: Understanding Transparency Dimensions

Before evaluating code, familiarize yourself with key transparency dimensions:

1. **Code Readability**: How easily the code can be read and understood
2. **Function Clarity**: How clear the purpose and behavior of functions/methods are
3. **Architecture Visibility**: How apparent the overall code structure and organization is
4. **Decision Explanations**: How well the reasoning behind code decisions is explained
5. **Documentation Completeness**: How thoroughly the code is documented

### Part 2: Transparency Evaluation

Evaluate three examples of AI-generated code for transparency. You can use:

- Code you've recently generated using an AI assistant
- Code generated by colleagues using AI assistance
- The sample code snippets provided below

**Sample 1: Data Processing Function**
```
def process_data(data, config=None):
    """Process input data based on configuration."""
    config = config or DEFAULT_CONFIG
    result = []
    for item in data:
        if not _is_valid(item):
            continue
        processed = {}
        for key, value in item.items():
            if key in config.get('exclude_fields', []):
                continue
            if key in config.get('transform_fields', {}):
                processed[key] = _apply_transform(value, config['transform_fields'][key])
            else:
                processed[key] = value
        if config.get('add_metadata', False):
            processed['_meta'] = {'processed_at': datetime.now().isoformat()}
        result.append(processed)
    return result
```

**Sample 2: Authentication Middleware**
```
class AuthMiddleware:
    """Middleware for handling authentication."""
    
    def __init__(self, settings):
        self.settings = settings
        self.cache = {}
    
    async def process_request(self, request):
        token = self._extract_token(request)
        if not token:
            return self._create_unauthorized_response("No token provided")
        
        user_id = self._get_user_id_from_cache(token)
        if not user_id:
            try:
                payload = self._decode_token(token)
                user_id = payload.get('sub')
                if not user_id:
                    return self._create_unauthorized_response("Invalid token payload")
                self._cache_user_id(token, user_id)
            except Exception as e:
                return self._create_unauthorized_response(f"Token validation failed: {str(e)}")
                
        request.user_id = user_id
        return None
```

**Sample 3: Recommendation Algorithm**
```
def generate_recommendations(user_id, item_count=5):
    """Generate personalized recommendations for a user."""
    user_history = get_user_history(user_id)
    if not user_history:
        return get_popular_items(item_count)
    
    user_vector = create_user_vector(user_history)
    candidate_items = get_candidate_items(user_id)
    
    scores = {}
    for item in candidate_items:
        item_vector = get_item_vector(item['id'])
        base_score = calculate_similarity(user_vector, item_vector)
        recency_boost = calculate_recency_boost(item['created_at'])
        popularity_factor = calculate_popularity_factor(item['interaction_count'])
        diversity_score = calculate_diversity(item, user_history)
        
        final_score = (base_score * 0.65) + (recency_boost * 0.1) + 
                     (popularity_factor * 0.15) + (diversity_score * 0.1)
        scores[item['id']] = final_score
    
    recommended_items = sorted(candidate_items, 
                             key=lambda x: scores[x['id']], 
                             reverse=True)[:item_count]
    
    return recommended_items
```

For each code sample, assess transparency across the five dimensions using this scoring system:
1 = Poor, 2 = Fair, 3 = Good, 4 = Excellent

Then, identify specific transparency issues:
- What parts of the code are difficult to understand?
- What assumptions are unclear?
- What decision rationales are missing?
- What broader context is needed?

### Part 3: Transparency Enhancement

For one of the code samples (or for your own AI-generated code), implement at least five transparency improvements:

1. **Improve Naming**: Rename variables, functions, or classes to better reflect their purpose
2. **Add Comments**: Add explanatory comments for complex or non-obvious code sections
3. **Enhance Documentation**: Improve function/method documentation with parameters, return values, and examples
4. **Extract Methods**: Break complex functions into smaller, well-named methods
5. **Add Context**: Create documentation that explains the broader context and purpose
6. **Make Implicit Explicit**: Convert implicit assumptions into explicit code or documentation
7. **Add Decision Rationales**: Document why specific approaches were chosen

### Part 4: Transparency Documentation Template

Create a documentation template for AI-generated code that enhances transparency. Your template should include:

- Purpose and scope section
- Function/method overview
- Parameter and return value documentation
- Example usage
- Decision rationale for key design choices
- Limitations and assumptions
- AI contribution disclosure

Apply your template to one of the code samples.

## Reflection Questions

After completing the exercise, reflect on the following questions:

1. What aspects of transparency are most often lacking in AI-generated code?

2. How does transparency affect your ability to maintain and extend code?

3. What techniques were most effective for improving code transparency?

4. How might your approach to prompting AI assistants change to improve transparency?

5. How can you balance the efficiency benefits of AI-assisted development with the need for transparency?

## Extension Activities

1. **Transparency Audit**: Review a larger AI-assisted project and audit it for transparency issues.

2. **Team Standards**: Develop transparency standards for AI-assisted development on your team.

3. **Transparency-Focused Prompting**: Experiment with different prompting techniques specifically aimed at improving transparency.

4. **Before and After Study**: Take a piece of non-transparent AI-generated code and fully refactor it for transparency. Compare the before and after versions for maintainability and understandability.

## Submission

Submit your transparency evaluation of the code samples, your enhanced version of one sample, and your transparency documentation template.
