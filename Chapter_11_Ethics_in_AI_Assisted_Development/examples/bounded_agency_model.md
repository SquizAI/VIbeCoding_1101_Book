# Bounded Agency Model

## Overview

The Bounded Agency Model provides a structured approach for maintaining developer agency while leveraging AI assistance. Rather than viewing agency as a binary state that is either present or absent, this model conceptualizes agency as existing within boundaries that can be deliberately shaped and managed.

## Model Foundation

The Bounded Agency Model is built on three key premises:

1. **Agency exists on a spectrum** rather than as a binary state
2. **Boundaries can be intentionally designed** to preserve essential agency
3. **Different domains require different agency boundaries** based on context, risk, and developer expertise

By applying this model, developers and teams can create frameworks that allow them to benefit from AI assistance while ensuring they maintain meaningful control and understanding of their work.

## Core Components

### 1. Agency Dimensions

The model identifies five key dimensions of developer agency:

#### Technical Understanding
The depth of comprehension a developer has about how their code works and why certain approaches were chosen.

**High Agency:** Developer can explain all aspects of the code's operation and the rationales for technical decisions.  
**Low Agency:** Developer cannot explain significant portions of the code or why certain approaches were implemented.

#### Decision Autonomy
The degree to which a developer makes intentional choices about code structure, approaches, and implementation details.

**High Agency:** Developer consciously evaluates and decides which AI suggestions to implement.  
**Low Agency:** Developer passively accepts AI suggestions without critical evaluation.

#### Skill Development
The continued growth of a developer's programming knowledge and abilities.

**High Agency:** Developer continues to learn and develop skills even while using AI assistance.  
**Low Agency:** Developer's skills plateau or deteriorate as they delegate thinking to AI.

#### Process Control
The developer's ability to guide the development process toward desired outcomes.

**High Agency:** Developer directs the AI rather than being directed by it.  
**Low Agency:** Developer follows AI guidance without shaping the direction.

#### Adaptation Capability
The ability to modify, extend, or debug code without heavy dependence on AI.

**High Agency:** Developer can confidently modify code without returning to AI for assistance.  
**Low Agency:** Developer struggles to modify code without returning to AI for help.

### 2. Boundary Setting

The model provides frameworks for establishing appropriate boundaries in each agency dimension:

#### Minimum Thresholds
Establishing minimum acceptable levels for each agency dimension based on:
- Project criticality and risk
- Developer experience level
- Domain complexity
- Organizational requirements

#### Agency Checkpoints
Specific points in the development process where agency is explicitly assessed:
- Before accepting substantial AI-generated code
- When making significant architectural decisions
- During code review processes
- At regular intervals during extended AI collaboration

#### Agency Preservation Practices
Specific strategies to maintain agency within established boundaries:
- Documentation of understanding
- Deliberate evaluation of AI suggestions
- Regular skill practice without AI
- Explicit decision-making processes

### 3. Contextual Adaptation

The model recognizes that appropriate agency boundaries differ based on context:

#### Risk-Based Adaptation
How agency boundaries should shift based on project risk:

**High-Risk Contexts** (safety-critical, financial, security):
- Require higher agency thresholds
- Need more frequent agency checkpoints
- Demand more rigorous documentation of understanding

**Low-Risk Contexts** (prototyping, internal tools, learning projects):
- Allow lower agency thresholds
- Need less frequent agency checkpoints
- Permit more exploration with AI assistance

#### Expertise-Based Adaptation
How agency boundaries should adapt based on developer expertise:

**Novice Developers:**
- Need stronger guardrails for technical understanding
- Benefit from more structured decision processes
- Require deliberate skill development focus

**Expert Developers:**
- Can operate with more flexible agency boundaries
- Can better judge when to delegate to AI versus maintain control
- Are better positioned to evaluate AI suggestions critically

#### Domain-Based Adaptation
How agency boundaries should vary across different technical domains:

**Novel or Complex Domains:**
- Require higher understanding thresholds
- Benefit from more conservative delegation
- Need more explicit agency checkpoints

**Familiar or Routine Domains:**
- Allow more flexible agency boundaries
- Permit more extensive AI delegation
- Need less frequent agency assessment

## Practical Application

### Agency Assessment

The model includes assessment tools to measure current agency levels:

#### Self-Assessment Questions
For each agency dimension, developers can ask:
- Can I explain how this code works and why this approach was chosen?
- Did I make conscious decisions about implementing AI suggestions?
- Am I developing my skills while using AI assistance?
- Am I directing the development process or following AI's lead?
- Could I modify this code without returning to AI for help?

#### Team Assessment Practices
Teams can implement:
- Code explanation exercises where developers explain AI-assisted code
- Random agency checks during code reviews
- Skill development tracking alongside AI usage metrics
- Periodic AI-free development periods

### Boundary Implementation

The model provides practical strategies for implementing agency boundaries:

#### Technical Understanding Boundaries
- Document explanation requirements for different code types
- Implement progressive disclosure in AI interactions
- Create understanding verification processes

#### Decision Autonomy Boundaries
- Establish decision criteria for evaluating AI suggestions
- Document decision points and rationales
- Implement approval processes for significant AI contributions

#### Skill Development Boundaries
- Identify core skills that must be maintained
- Schedule deliberate practice without AI assistance
- Create learning opportunities alongside AI usage

#### Process Control Boundaries
- Define areas where developers must lead versus where AI can lead
- Establish reflection points during development process
- Create process documentation requirements

#### Adaptation Capability Boundaries
- Implement modification exercises for AI-generated code
- Create extension requirements for AI-assisted components
- Establish debugging processes that build capability

### Organizational Integration

The model includes approaches for organizational adoption:

#### Policy Development
Guidelines for creating organizational policies that support bounded agency:
- Agency expectations for different project types
- Documentation requirements for AI-assisted work
- Review processes focused on agency preservation

#### Team Structures
Recommendations for team configurations that support agency:
- Balanced expertise distribution
- Agency-preserving roles and responsibilities
- Collaborative approaches that maintain individual agency

#### Metrics and Evaluation
Approaches for measuring and evaluating agency within teams:
- Agency health indicators
- AI dependence assessment
- Skill development tracking

## Case Study: Team Horizon

### Context
Team Horizon, a software development team at a mid-sized healthcare technology company, implemented the Bounded Agency Model when adopting advanced AI coding assistants.

### Challenge
Initial AI adoption led to:
- Junior developers accepting AI suggestions without understanding
- Inconsistent documentation of AI-assisted decisions
- Growing dependence on AI for routine tasks
- Difficulty modifying AI-generated code during maintenance

### Implementation
The team applied the Bounded Agency Model:

1. **Assessment**: Evaluated current agency levels across dimensions.

2. **Boundary Setting**:
   - Established minimum understanding thresholds based on code criticality
   - Created decision documentation requirements for AI-assisted code
   - Implemented weekly AI-free development periods for skill maintenance
   - Developed a modification exercise program for AI-generated code

3. **Contextual Adaptation**:
   - Created different agency requirements for patient-facing versus internal systems
   - Tailored agency expectations to developer experience levels
   - Adjusted agency boundaries based on technology familiarity

### Results
After six months:
- Improved code understanding across the team
- More selective and intentional use of AI assistance
- Continued skill development alongside productivity gains
- Enhanced ability to maintain and extend code
- Greater confidence in AI-assisted work quality

## Conclusion

The Bounded Agency Model provides a nuanced framework for maintaining developer agency while gaining the benefits of AI assistance. By recognizing agency as existing within boundaries that can be intentionally shaped, developers and organizations can create healthier, more sustainable approaches to AI-assisted development.

Rather than rejecting AI assistance due to agency concerns or accepting diminished agency as an inevitable consequence of AI adoption, the model offers a middle path that preserves essential agency while embracing the advantages of AI collaboration.

## References

1. Bryson, J., & Winfield, A. (2023). "Standardizing ethical design for artificial intelligence and autonomous systems." *Computer*, 50(5), 116-119.

2. Lee, M. K., & Baytas, J. D. (2024). "Human agency in AI-assisted work: A meta-analysis of emerging patterns." *Journal of Human-Computer Interaction*, 41(2), 203-228.

3. Kahneman, D., & Klein, G. (2009). "Conditions for intuitive expertise: A failure to disagree." *American Psychologist*, 64(6), 515-526.

4. Orlikowski, W. J. (2022). "The duality of technology: Rethinking the concept of technology in organizations." *Organization Science*, 33(3), 398-427.

5. Zhang, Y., & Shrum, L. J. (2023). "The psychology of agency: Understanding human autonomy in human-AI collaboration." *Annual Review of Psychology*, 74, 295-318.
